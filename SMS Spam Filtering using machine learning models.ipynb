{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ecb1b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86028efc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\veni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2152690e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5568 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     title                                               body\n",
       "0      ham  I've been searching for the right words to tha...\n",
       "1     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "2      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "3      ham  Even my brother is not like to speak with me. ...\n",
       "4      ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "...    ...                                                ...\n",
       "5563  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5564   ham               Will ü b going to esplanade fr home?\n",
       "5565   ham  Pity, * was in mood for that. So...any other s...\n",
       "5566   ham  The guy did some bitching but I acted like i'd...\n",
       "5567   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5568 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullcorpus=pd.read_csv(\"SMSSpamCollection (1).tsv\",sep=\"\\t\",header=None)\n",
    "fullcorpus=fullcorpus.rename(columns={0:\"title\",1:\"body\"})\n",
    "fullcorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "061ae1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5568, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullcorpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5345616c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4822\n",
       "spam     746\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullcorpus.title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c4ebf32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    0\n",
       "body     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullcorpus.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23582671",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5568 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     title                                               body\n",
       "0      ham  I've been searching for the right words to tha...\n",
       "1     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "2      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "3      ham  Even my brother is not like to speak with me. ...\n",
       "4      ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "...    ...                                                ...\n",
       "5563  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5564   ham               Will ü b going to esplanade fr home?\n",
       "5565   ham  Pity, * was in mood for that. So...any other s...\n",
       "5566   ham  The guy did some bitching but I acted like i'd...\n",
       "5567   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5568 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullcorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5327548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\veni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\veni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "ps=nltk.PorterStemmer()\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "wnl=nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4d4b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    text=\"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text\n",
    "\n",
    "def tokenized_list(sentence):\n",
    "    text_sentence=re.split('\\W+',sentence)\n",
    "    return text_sentence\n",
    "\n",
    "def removing_stopwords(text):\n",
    "    no_stopword = [char for char in text if char not in stopword]\n",
    "    return no_stopword\n",
    "\n",
    "def stemming_word(text):\n",
    "    stemmed_word = [ps.stem(char) for char in text]\n",
    "    return stemmed_word\n",
    "\n",
    "def lemmatizing(word_list):\n",
    "    lemmatized_word = [wnl.lemmatize(word) for word in word_list]\n",
    "    return lemmatized_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "868a2b32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopword=nltk.corpus.stopwords.words(\"english\")\n",
    "stopwords=stopword.copy()\n",
    "fullcorpus[\"punc_removed_body\"]=fullcorpus[\"body\"].apply(lambda x: remove_punctuation(x))\n",
    "fullcorpus[\"tokenized_body\"]=fullcorpus[\"punc_removed_body\"].apply(lambda x: tokenized_list(x.lower()))\n",
    "fullcorpus[\"stopword_removed_list\"]=fullcorpus[\"tokenized_body\"].apply(lambda x:removing_stopwords(x))\n",
    "fullcorpus[\"Stem_word\"]=fullcorpus[\"stopword_removed_list\"].apply(lambda x:stemming_word(x))\n",
    "fullcorpus[\"lemmatized_words\"]=fullcorpus[\"stopword_removed_list\"].apply(lambda x:lemmatizing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ea16712",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>punc_removed_body</th>\n",
       "      <th>tokenized_body</th>\n",
       "      <th>stopword_removed_list</th>\n",
       "      <th>Stem_word</th>\n",
       "      <th>lemmatized_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>Ive been searching for the right words to than...</td>\n",
       "      <td>[ive, been, searching, for, the, right, words,...</td>\n",
       "      <td>[ive, searching, right, words, thank, breather...</td>\n",
       "      <td>[ive, search, right, word, thank, breather, pr...</td>\n",
       "      <td>[ive, searching, right, word, thank, breather,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>Even my brother is not like to speak with me T...</td>\n",
       "      <td>[even, my, brother, is, not, like, to, speak, ...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aids...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aid,...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aid,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
       "      <td>[i, have, a, date, on, sunday, with, will]</td>\n",
       "      <td>[date, sunday]</td>\n",
       "      <td>[date, sunday]</td>\n",
       "      <td>[date, sunday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>[this, is, the, 2nd, time, we, have, tried, 2,...</td>\n",
       "      <td>[2nd, time, tried, 2, contact, u, u, 750, poun...</td>\n",
       "      <td>[2nd, time, tri, 2, contact, u, u, 750, pound,...</td>\n",
       "      <td>[2nd, time, tried, 2, contact, u, u, 750, poun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>Will ü b going to esplanade fr home</td>\n",
       "      <td>[will, ü, b, going, to, esplanade, fr, home]</td>\n",
       "      <td>[ü, b, going, esplanade, fr, home]</td>\n",
       "      <td>[ü, b, go, esplanad, fr, home]</td>\n",
       "      <td>[ü, b, going, esplanade, fr, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>Pity  was in mood for that Soany other suggest...</td>\n",
       "      <td>[pity, was, in, mood, for, that, soany, other,...</td>\n",
       "      <td>[pity, mood, soany, suggestions]</td>\n",
       "      <td>[piti, mood, soani, suggest]</td>\n",
       "      <td>[pity, mood, soany, suggestion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>The guy did some bitching but I acted like id ...</td>\n",
       "      <td>[the, guy, did, some, bitching, but, i, acted,...</td>\n",
       "      <td>[guy, bitching, acted, like, id, interested, b...</td>\n",
       "      <td>[guy, bitch, act, like, id, interest, buy, som...</td>\n",
       "      <td>[guy, bitching, acted, like, id, interested, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>Rofl Its true to its name</td>\n",
       "      <td>[rofl, its, true, to, its, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5568 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     title                                               body  \\\n",
       "0      ham  I've been searching for the right words to tha...   \n",
       "1     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "2      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "3      ham  Even my brother is not like to speak with me. ...   \n",
       "4      ham                I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "...    ...                                                ...   \n",
       "5563  spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5564   ham               Will ü b going to esplanade fr home?   \n",
       "5565   ham  Pity, * was in mood for that. So...any other s...   \n",
       "5566   ham  The guy did some bitching but I acted like i'd...   \n",
       "5567   ham                         Rofl. Its true to its name   \n",
       "\n",
       "                                      punc_removed_body  \\\n",
       "0     Ive been searching for the right words to than...   \n",
       "1     Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "2     Nah I dont think he goes to usf he lives aroun...   \n",
       "3     Even my brother is not like to speak with me T...   \n",
       "4                     I HAVE A DATE ON SUNDAY WITH WILL   \n",
       "...                                                 ...   \n",
       "5563  This is the 2nd time we have tried 2 contact u...   \n",
       "5564                Will ü b going to esplanade fr home   \n",
       "5565  Pity  was in mood for that Soany other suggest...   \n",
       "5566  The guy did some bitching but I acted like id ...   \n",
       "5567                          Rofl Its true to its name   \n",
       "\n",
       "                                         tokenized_body  \\\n",
       "0     [ive, been, searching, for, the, right, words,...   \n",
       "1     [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "2     [nah, i, dont, think, he, goes, to, usf, he, l...   \n",
       "3     [even, my, brother, is, not, like, to, speak, ...   \n",
       "4            [i, have, a, date, on, sunday, with, will]   \n",
       "...                                                 ...   \n",
       "5563  [this, is, the, 2nd, time, we, have, tried, 2,...   \n",
       "5564       [will, ü, b, going, to, esplanade, fr, home]   \n",
       "5565  [pity, was, in, mood, for, that, soany, other,...   \n",
       "5566  [the, guy, did, some, bitching, but, i, acted,...   \n",
       "5567                   [rofl, its, true, to, its, name]   \n",
       "\n",
       "                                  stopword_removed_list  \\\n",
       "0     [ive, searching, right, words, thank, breather...   \n",
       "1     [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "2     [nah, dont, think, goes, usf, lives, around, t...   \n",
       "3     [even, brother, like, speak, treat, like, aids...   \n",
       "4                                        [date, sunday]   \n",
       "...                                                 ...   \n",
       "5563  [2nd, time, tried, 2, contact, u, u, 750, poun...   \n",
       "5564                 [ü, b, going, esplanade, fr, home]   \n",
       "5565                   [pity, mood, soany, suggestions]   \n",
       "5566  [guy, bitching, acted, like, id, interested, b...   \n",
       "5567                                 [rofl, true, name]   \n",
       "\n",
       "                                              Stem_word  \\\n",
       "0     [ive, search, right, word, thank, breather, pr...   \n",
       "1     [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
       "2     [nah, dont, think, goe, usf, live, around, tho...   \n",
       "3     [even, brother, like, speak, treat, like, aid,...   \n",
       "4                                        [date, sunday]   \n",
       "...                                                 ...   \n",
       "5563  [2nd, time, tri, 2, contact, u, u, 750, pound,...   \n",
       "5564                     [ü, b, go, esplanad, fr, home]   \n",
       "5565                       [piti, mood, soani, suggest]   \n",
       "5566  [guy, bitch, act, like, id, interest, buy, som...   \n",
       "5567                                 [rofl, true, name]   \n",
       "\n",
       "                                       lemmatized_words  \n",
       "0     [ive, searching, right, word, thank, breather,...  \n",
       "1     [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
       "2     [nah, dont, think, go, usf, life, around, though]  \n",
       "3     [even, brother, like, speak, treat, like, aid,...  \n",
       "4                                        [date, sunday]  \n",
       "...                                                 ...  \n",
       "5563  [2nd, time, tried, 2, contact, u, u, 750, poun...  \n",
       "5564                 [ü, b, going, esplanade, fr, home]  \n",
       "5565                    [pity, mood, soany, suggestion]  \n",
       "5566  [guy, bitching, acted, like, id, interested, b...  \n",
       "5567                                 [rofl, true, name]  \n",
       "\n",
       "[5568 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullcorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ba7430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullcorpus=fullcorpus.drop([\"tokenized_body\",\"punc_removed_body\",\"stopword_removed_list\",\"Stem_word\",\"lemmatized_words\"],axis=1)\n",
    "data=fullcorpus.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4101d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative method to clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97f5e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    #text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    text = [wnl.lemmatize(word) for word in tokens if word not in stopwords]   \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd118dbe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# creating count vectorizer\n",
    "count_vect = CountVectorizer(analyzer=clean_text)\n",
    "X_counts = count_vect.fit_transform(data['body'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb855e8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>8904</th>\n",
       "      <th>8905</th>\n",
       "      <th>8906</th>\n",
       "      <th>8907</th>\n",
       "      <th>8908</th>\n",
       "      <th>8909</th>\n",
       "      <th>8910</th>\n",
       "      <th>8911</th>\n",
       "      <th>8912</th>\n",
       "      <th>8913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5568 rows × 8914 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     ...  8904  \\\n",
       "0        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "5563     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "5564     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "5565     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "5566     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "5567     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "      8905  8906  8907  8908  8909  8910  8911  8912  8913  \n",
       "0        0     0     0     0     0     0     0     0     0  \n",
       "1        0     0     0     0     0     0     0     0     0  \n",
       "2        0     0     0     0     0     0     0     0     0  \n",
       "3        0     0     0     0     0     0     0     0     0  \n",
       "4        0     0     0     0     0     0     0     0     0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "5563     0     0     0     0     0     0     0     0     0  \n",
       "5564     0     0     0     0     0     0     1     0     0  \n",
       "5565     0     0     0     0     0     0     0     0     0  \n",
       "5566     0     0     0     0     0     0     0     0     0  \n",
       "5567     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5568 rows x 8914 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.DataFrame(X_counts.toarray())\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96a4583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.copy()\n",
    "y = data.iloc[:,0].values\n",
    "labelencoder_y=LabelEncoder()\n",
    "y=labelencoder_y.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfc5d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_buiding(x,y,model):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)\n",
    "    classifier = model\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'For the {classifier} model, the values are given below :')\n",
    "    print(f'The confusion matrix of is:\\n\\n{cm}')\n",
    "    accuracy=accuracy_score(y_test, y_pred)\n",
    "    print(f'\\nThe accuracy score of the is: {accuracy}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0f2ed62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the GaussianNB() model, the values are given below :\n",
      "The confusion matrix of is:\n",
      "\n",
      "[[853 112]\n",
      " [ 13 136]]\n",
      "\n",
      "The accuracy score of the is: 0.8877917414721723\n",
      "\n",
      "For the LogisticRegression() model, the values are given below :\n",
      "The confusion matrix of is:\n",
      "\n",
      "[[964   1]\n",
      " [ 23 126]]\n",
      "\n",
      "The accuracy score of the is: 0.9784560143626571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_buiding(X,y,GaussianNB())\n",
    "model_buiding(X,y,LogisticRegression())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
